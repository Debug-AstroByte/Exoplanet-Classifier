{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fc6e863-d198-4984-acba-7878bbad2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas matplotlib seaborn scikit-learn tensorflow lightkurve joblib astropy scipy shap streamlit --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e69377-3ea2-4e95-8a48-55015f2a0443",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing Libraries\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import classification_report, roc_auc_score, precision_recall_curve, auc, confusion_matrix, ConfusionMatrixDisplay\n",
    "import joblib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from lightkurve import search_lightcurvefile\n",
    "from astropy.stats import sigma_clip\n",
    "from scipy.signal import convolve\n",
    "import shap\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f188b5a-6aac-4134-bfae-9d840c4d2676",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your KOI CSV\n",
    "df = pd.read_csv('kepler_koi.csv')\n",
    "df.head()\n",
    "df.columns\n",
    "df['koi_disposition'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409554ca-1f16-480e-b44f-786f56ca9093",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parameters for Large-Scale Real Kepler Pipeline\n",
    "CACHE_DIR = '/content/kepler_cache'\n",
    "os.makedirs(CACHE_DIR, exist_ok=True)\n",
    "N_SAMPLES_PER_CLASS = 200\n",
    "N_BINS = 400\n",
    "MAX_LEN = N_BINS\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e127fc7-d80d-4e7e-9d93-4fe98e3136da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Downloading and Caching Kepler Light Curves\n",
    "def download_lightcurve_cached(kepid, max_retries = 3, delay = 3):\n",
    "    cache_path = os.path.join(CACHE_DIR, f'KIC{int(kepid)}.fits')\n",
    "    for attempt in range(max_entries):\n",
    "        try:\n",
    "            if os.path.exists(cache_path):\n",
    "                from lightkurve import LightCurveFile\n",
    "                lcfile = LightCurveFile(cache_path)\n",
    "            else:\n",
    "                lcfile = search_lightcurvefile(f'KIC {kepid}',mission='Kepler').download(path=cache_path)\n",
    "            lc = lcfile.PDCSAP_FLUX.remove_nans()\n",
    "            return lc\n",
    "        except Exception as e:\n",
    "            print(f'[Attempt {attempt+1}] Failed for {kepid}: {e}')\n",
    "            time.sleep(delay)\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "651616d2-f55f-4752-b485-efcf064d2bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing Helpers\n",
    "def detrend_and_normalize(lc, window_length=401):\n",
    "    try:\n",
    "        flat = lc.flatten(window_length=window_length)\n",
    "    except Exception:\n",
    "        flat = lc.copy()\n",
    "    norm = (flat.flux / np.nanmedian(flat.flux)) - 1.0\n",
    "    return np.array(norm)\n",
    "def fold_and_resample(lc, period, epoch_time, n_bins=N_BINS):\n",
    "    try:\n",
    "        folded = lc.fold(period=period, t0=epoch_time)\n",
    "        phase_vals = (folded.time.value - np.nanmedian(folded.time.value)) /\n",
    "        period\n",
    "        grid = np.linspace(-0.5, 0.5, n_bins)\n",
    "        mask = np.isfinite(phase_vals) & np.isfinite(folded.flux)\n",
    "        if mask.sum() < (n_bins // 10):\n",
    "            return None\n",
    "        resampled = np.interp(grid, phase_vals[mask], folded.flux[mask],\n",
    "        left=np.nanmedian(folded.flux), right=np.nanmedian(folded.flux))\n",
    "        resampled = (resampled / np.nanmedian(resampled)) - 1.0\n",
    "        return resampled\n",
    "    except Exception:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbc7de7-edf8-49fe-89e0-24d47b6e20eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Safe Function to Extract Period and Epoch\n",
    "def safe_get_period_and_epoch(row):\n",
    "    period, epoch = None, None\n",
    "    for c in ['koi_period', 'period', 'kepoi_period']:\n",
    "        if c in row.index and not pd.isna(row[c]):\n",
    "            period = float(row[c]);\n",
    "            break\n",
    "    for c in ['koi_time0bk', 'koi_time0', 'time0bk', 'epoch']:\n",
    "        if c in row.index and not pd.isna(row[c]):\n",
    "            epoch = float(row[c]);\n",
    "            break\n",
    "    return period, epoch\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf60dd50-ff87-42ff-a0b2-0c7a2f2a9131",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sample 200 Positives\n",
    "confirmed_df = df[df['koi_disposition'].str.upper() == \"CONFIRMED\"]\n",
    "false_df = df[df['koi_disposition'].str.upper().str.contains('FALSE', na = False)]\n",
    "\n",
    "confirmed_sample = confirmed_df.sample(min(N_SAMPLES_PER_CLASS, len(confirmed_def)), random_state = 42)\n",
    "false_sample = false_df.sample(min(N_SAMPLES_PER_CLASS, len(false_df)),\n",
    "random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba7d00c-c356-4c2b-b133-5e01fe5986fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Parallel Preprocessing for Efficiency\n",
    "X_list, y_list = [], []\n",
    "\n",
    "def process_row(row, label) :\n",
    "    kepid = int(row['kepid'])\n",
    "    lc = download_lightcurve_cached(kepid)\n",
    "    if lc is None: return None\n",
    "    period, epoch = safe_get_period_and_epoch(row)\n",
    "    if period and epoch:\n",
    "        res = fold_and_resample(lc, period, epoch, n_bins=N_BINS)\n",
    "        if res is not None: return res, label\n",
    "        arr = detrend_and_normalize(lc)\n",
    "        arr_res = np.interp(np.linspace(0,1,MAX_LEN), np.linspace(0,1,len(arr)), arr)\n",
    "        return arr_res, label\n",
    "\n",
    "with ThreadPoolExecutor(max_workers = 8)as ex :\n",
    "    futures = [ex.submit(process_row, row, 1) for _, row in confirmed_sample.iterrows()] + [ex.submit(process_row, row, 0) for _, row in\n",
    "false_sample.iterrows()] \n",
    "    for f in as_completed(futures):\n",
    "        res = f.result()\n",
    "        if res: X_list.append(res[0]); y_list.appen(res[1])\n",
    "X_arr = = np.expand_dims(np.array(X_list, dtype='float32'), -1)\n",
    "y_arr = np.array(y_list, dtype='int64')\n",
    "print('Dataset shape:', X_arr.shape, 'Class distribution:', np.bincount(y_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dacbaa55-64ef-40e8-ac75-d28778ecd257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train/Test Split and Class Weights\n",
    "X_train X_test, y_train, y_test = train_test_split(X_arr, y_arr, test_size = 42, stratify = y_arr, random_state 42)\n",
    "classes = np.unique(y_train)\n",
    "class_weights = compute_class_weight('balanced', classes = classes, y = y_train)\n",
    "class_weight_dict = {int(c): float(w) for c, w in zip(classes, class_weights)}\n",
    "print('Class Weights:', class_weights_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1195edc-eb67-4e31-92a6-f4e4c138e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1D CNN Definition\n",
    "def build_cnn(input_shape):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "    x = layers.Conv1D(32, 9, padding='same', activation='relu')(inputs)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(64, 5, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(2)(x)\n",
    "    x = layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Conv1D(128, 3, padding='same', activation='relu')(x)\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    outputs = layers.Dense(1, activation='sigmoid')(x)\n",
    "    model = models.Model(inputs, outputs)\n",
    "    model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss='binary_crossentropy', metrics=['accuracy', tf.keras.metrics.AUC(name='auc')])\n",
    "    return model\n",
    "model = build_cnn(X_train.shape[1:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dda33078-fd0f-4a1a-88ce-0210a02a254e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training with #Callbacks\n",
    "cb = [callbacks.EarlyStopping(monitor = 'val_auc', patience = 6, restore_best_weights = True, mode = 'max'), \n",
    "      callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.5, patience = 3, min_lr = 1e-6, verbose = 1), \n",
    "      callbacks.ModelCheckpoint('best_cnn_kepler.h5', monitor  = 'val_auc', save_best_only = True, mode = 'max')]\n",
    "history = model.fit(X_train, y_train, validation_split=0.15, epochs=EPOCHS, batch_size=BATCH_SIZE, class_weight=class_weight_dict, callbacks=cb, verbose=2)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4812a38-776a-47d5-98bc-dea6cf84c309",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation, ROC, PR, and Confusion Matrix\n",
    "y_pred = model.predict(X_test).ravel()\n",
    "\n",
    "#ROC CURVE \n",
    "from sklearn.metrics import roc_curve, precision_recall_curve, auc fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "#Precision Recall Curve\n",
    "precision, recall, _ = precision_recall_curve(y_test, y_pred)\n",
    "pr_auc = auc(recall, precision)\n",
    "\n",
    "plt.figure(figsize=(12,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(fpr, tpr, label=f'ROC AUC={roc_auc:.3f}')\n",
    "plt.plot([0,1],[0,1],'--',color='gray')\n",
    "plt.xlabel('False Positive Rate'); plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve'); plt.legend()\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(recall, precision, label=f'PR AUC={pr_auc:.3f}')\n",
    "plt.xlabel('Recall'); plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve'); plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "cm = confusion_matrix(y_test, (y_pred>0.5).astype(int))\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['FalsePositive','Confirmed'])\n",
    "disp.plot(cmap='Blues'); plt.show()\n",
    "\n",
    "# Visualize top predicted planets\n",
    "for i in np.argsort(y_pred)[-6:][::-1]:\n",
    "    plt.figure(figsize=(8,3))\n",
    "    plt.plot(X_test[i].squeeze(), label=f'pred={y_pred[i]:.3f}, label={y_test[i]}')\n",
    "    plt.title('Folded / Resampled Light Curve')\n",
    "    plt.xlabel('Phase bin'); plt.legend(); plt.show()\n",
    "    \n",
    "# Save preprocessed arrays\n",
    "np.savez_compressed('kepler_200_dataset.npz', X_train=X_train, X_test=X_test,\n",
    "y_train=y_train, y_test=y_test)\n",
    "model.save('cnn_kepler_200_v2.h5')\n",
    "print('Saved dataset and CNN model.')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jupyterenv)",
   "language": "python",
   "name": "jupyterenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
